---
layout: post
title: AI Has Entered the Chat
subtitle: Humans, AI and the Art of Collaboration
permalink: ai-entered-chat
---

This article accompanies the talk at CraftConf 2023.

<h2><strong>üéâüçø Here from Craft Conference? <a class="twitter-share-button" href="https://twitter.com/intent/tweet?text=I%27m%20listening%20to%20@frankc%20talk%20about%20generative%20agents%20More%3A%20https://frankc.net/ai-entered-chat" data-size="large">Tweet</a> and share how I'm wrong</strong></h2>
<h3>üéØ Are you up to try this yourself? https://forms.gle/gYATDmrPmnCxGGoaA</h3>

[ai-entered-chat-intro]: /img-posts/ai-entered-chat-intro.png

**üí° Abstract**

In this talk, I will explore the potential of integrating large language models and generative artificial intelligence (AI) agents into our work processes. Specifically, we‚Äôll examine how natural language interactions with AI-powered agents, including APIs and infrastructure, can create a new form of collaboration while keeping the human-in-the-loop. As an industry, we have only just begun to tap into the possibilities of AI technology.

I‚Äôll share some of my preliminary findings and discuss the opportunities presented by AI-enhanced coworkers. By delving deeper into their capabilities, we can understand how these agents can assist us in our existing workflows. Addressing the big questions surrounding the safe, ethical, and effective use of this technology is critical to its successful implementation.

My motivation for this talk stems from my desire to help people make better decisions and to create technologies that connect them better with their true objectives. I‚Äôll reference real-world examples showcasing the benefits and challenges of integrating large language models and AI agents in work processes.

Please note that this talk is separate from my software development and leadership roles at Slack.

[![How should we introduce this topic?][ai-entered-chat-intro]](/img-posts/ai-entered-chat-intro.png)

**üîó References**

Here is a list of links mentioned in the document with their corresponding titles and short summaries:

- [https://historyofinformation.com/detail.php?entryid=4724](https://historyofinformation.com/detail.php?entryid=4724) - A brief history of advanced chess tournaments that centered on human-computer teams playing chess against each other.
- [https://en.chessbase.com/post/dark-horse-zacks-wins-freestyle-che-tournament](https://en.chessbase.com/post/dark-horse-zacks-wins-freestyle-che-tournament) - A Chessbase article about an example of amateur chess players with lower-end chess software beating grand masters with high-end chess software in a freestyle chess tournament.
- [https://arxiv.org/abs/2210.03629](https://arxiv.org/abs/2210.03629) - "ReAct: Reasoning and Acting with Language Models" is a paper about a new method that uses large language models to generate reasoning traces and task-specific actions in an interleaved manner, demonstrating improved performance on a diverse set of tasks.
- [https://arxiv.org/abs/2205.00445](https://arxiv.org/abs/2205.00445) - "Modular Reasoning, Knowledge, and Language" is a paper about a new architecture for artificial intelligence that uses modular components to enable agents to reason and interact in complex environments.
- [https://medium.com/syncedreview/stanford-u-googles-generative-agents-produce-believable-proxies-of-human-behaviours-406d34b595c3](https://medium.com/syncedreview/stanford-u-googles-generative-agents-produce-believable-proxies-of-human-behaviours-406d34b595c3) - A Medium article about a study where a team from Stanford University and Google Research created agents that use generative models to simulate humanlike behaviors and demonstrated believable proxies of humanlike behaviors in remembering, planning, reacting, and reflecting.
- [https://arxiv.org/abs/2304.03442](https://arxiv.org/abs/2304.03442) - An arXiv paper about generative agents that draw on generative models to simulate both individual and emergent group behaviors that are humanlike and based on their identities, changing experiences, and environments.
- [https://reverie.herokuapp.com/arXiv_Demo/#](https://reverie.herokuapp.com/arXiv_Demo/#) - A demo of Reverie, a platform that enables real-time interaction with research papers through a chat interface.
- [https://github.com/hwchase17/langchain](https://github.com/hwchase17/langchain) - Github repository for Langchain, a framework for building multi-agent systems that use language models to communicate and reason.
- [https://simonwillison.net/2023/Apr/25/dual-llm-pattern/](https://simonwillison.net/2023/Apr/25/dual-llm-pattern/) - A blog post by Simon Willison about dual LLM patterns, an approach that involves training two language models to work together to resist prompt attacks.
- [https://simonwillison.net/2023/Apr/14/worst-that-can-happen/](https://simonwillison.net/2023/Apr/14/worst-that-can-happen/) - A blog post by Simon Willison about the worst that can happen with large language models and how to mitigate those risks.
- [https://twitter.com/karpathy/status/1655994367033884672?s=12](https://twitter.com/karpathy/status/1655994367033884672?s=12) - A tweet by Andrej Karpathy about fine-tuning language models and how it can be analogous to expertise in people, with examples of describing tasks in words, giving examples of solving tasks, and allowing people to practice tasks.
- [https://github.com/mayooear/gpt4-pdf-chatbot-langchain](https://github.com/mayooear/gpt4-pdf-chatbot-langchain) - A Github repository for a GPT-4 PDF chatbot built on Langchain.
- [https://twitter.com/ttunguz/status/1658519374632714268?s=12](https://twitter.com/ttunguz/status/1658519374632714268?s=12) - A tweet by Tomasz Tunguz about when to choose a large model versus a small model for machine learning, with considerations such as time to ship, the need for intellectual property around machine learning, and the use of proprietary or sensitive data.
- [https://github.com/brexhq/prompt-engineering](https://github.com/brexhq/prompt-engineering) - A Github repository for a Python library that provides a set of tools for fine-tuning large language models.
- [https://twitter.com/ricburton/status/1657425842304057345?s=12](https://twitter.com/ricburton/status/1657425842304057345?s=12) - A tweet by Richard Burton about models leaking data and the potential risks of fine-tuning.
